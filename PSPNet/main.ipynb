{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple PSPNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using simple skip backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(X,filters,block):\n",
    "    # resiudal block with dilated convolutions\n",
    "    # add skip connection at last after doing convoluion operation to input X\n",
    "    \n",
    "    b = 'block_'+str(block)+'_'\n",
    "    f1,f2,f3 = filters\n",
    "    X_skip = X\n",
    "    # block_a\n",
    "    X = Convolution2D(filters=f1,kernel_size=(1,1),dilation_rate=(1,1),\n",
    "                      padding='same',kernel_initializer='he_normal',name=b+'a')(X)\n",
    "    X = BatchNormalization(name=b+'batch_norm_a')(X)\n",
    "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_a')(X)\n",
    "    # block_b\n",
    "    X = Convolution2D(filters=f2,kernel_size=(3,3),dilation_rate=(2,2),\n",
    "                      padding='same',kernel_initializer='he_normal',name=b+'b')(X)\n",
    "    X = BatchNormalization(name=b+'batch_norm_b')(X)\n",
    "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_b')(X)\n",
    "    # block_c\n",
    "    X = Convolution2D(filters=f3,kernel_size=(1,1),dilation_rate=(1,1),\n",
    "                      padding='same',kernel_initializer='he_normal',name=b+'c')(X)\n",
    "    X = BatchNormalization(name=b+'batch_norm_c')(X)\n",
    "    # skip_conv\n",
    "    X_skip = Convolution2D(filters=f3,kernel_size=(3,3),padding='same',name=b+'skip_conv')(X_skip)\n",
    "    X_skip = BatchNormalization(name=b+'batch_norm_skip_conv')(X_skip)\n",
    "    # block_c + skip_conv\n",
    "    X = Add(name=b+'add')([X,X_skip])\n",
    "    X = ReLU(name=b+'relu')(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_feature_maps(input_layer):\n",
    "    # base covolution module to get input image feature maps \n",
    "    \n",
    "    # block_1\n",
    "    base = conv_block(input_layer,[32,32,64],'1')\n",
    "    # block_2\n",
    "    base = conv_block(base,[64,64,128],'2')\n",
    "    # block_3\n",
    "    base = conv_block(base,[128,128,256],'3')\n",
    "    return base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pyramid pooling module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyramid_feature_maps(input_layer):\n",
    "    # pyramid pooling module\n",
    "    base = base_feature_maps(input_layer)\n",
    "    # red\n",
    "    red = GlobalAveragePooling2D(name='red_pool')(base)\n",
    "    red = tf.keras.layers.Reshape((1,1,256))(red)\n",
    "    red = Convolution2D(filters=64,kernel_size=(1,1),name='red_1_by_1')(red)\n",
    "    red = UpSampling2D(size=256,interpolation='bilinear',name='red_upsampling')(red)\n",
    "    # yellow\n",
    "    yellow = AveragePooling2D(pool_size=(2,2),name='yellow_pool')(base)\n",
    "    yellow = Convolution2D(filters=64,kernel_size=(1,1),name='yellow_1_by_1')(yellow)\n",
    "    yellow = UpSampling2D(size=2,interpolation='bilinear',name='yellow_upsampling')(yellow)\n",
    "    # blue\n",
    "    blue = AveragePooling2D(pool_size=(4,4),name='blue_pool')(base)\n",
    "    blue = Convolution2D(filters=64,kernel_size=(1,1),name='blue_1_by_1')(blue)\n",
    "    blue = UpSampling2D(size=4,interpolation='bilinear',name='blue_upsampling')(blue)\n",
    "    # green\n",
    "    green = AveragePooling2D(pool_size=(8,8),name='green_pool')(base)\n",
    "    green = Convolution2D(filters=64,kernel_size=(1,1),name='green_1_by_1')(green)\n",
    "    green = UpSampling2D(size=8,interpolation='bilinear',name='green_upsampling')(green)\n",
    "    # base + red + yellow + blue + green\n",
    "    return tf.keras.layers.concatenate([base,red,yellow,blue,green])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple pspnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_conv_module(input_layer):\n",
    "    X = pyramid_feature_maps(input_layer)\n",
    "    X = Convolution2D(filters=3,kernel_size=3,padding='same',name='last_conv_3_by_3')(X)\n",
    "    X = BatchNormalization(name='last_conv_3_by_3_batch_norm')(X)\n",
    "    X = Activation('sigmoid',name='last_conv_relu')(X)\n",
    "    X = tf.keras.layers.Flatten(name='last_conv_flatten')(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_PSPNet(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    output_layer = last_conv_module(input_layer)\n",
    "    \n",
    "    model = tf.keras.models.Model(input_layer, output_layer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_PSPNet((256, 256 , 3 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_folder=\"./cityscapes_data/dataset/train/\"\n",
    "val_folder = \"././cityscapes_data/dataset/val/\"\n",
    "\n",
    "def get_images_masks(path):\n",
    "    names=os.listdir(path)\n",
    "    img_g,img_m=[],[]\n",
    "    for name in names:\n",
    "        img=cv2.imread(path+name)\n",
    "        img=cv2.normalize(img,None,0,1,cv2.NORM_MINMAX,cv2.CV_32F)\n",
    "        img=img[:,:,::-1]\n",
    "        img_g.append(img[:,:256])\n",
    "        img_m.append(np.reshape(img[:,256:],(256*256*3)))\n",
    "        del img\n",
    "    del names\n",
    "    return img_g,img_m\n",
    "        \n",
    "#train_imgs,train_masks=get_images_masks(train_folder)\n",
    "val_imgs,val_masks=get_images_masks(val_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = np.array(val_imgs, np.float32)\n",
    "y_valid = np.array(val_masks, np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape:  (200, 256, 256, 3)\n",
      "Masks Shape:  (200, 196608)\n"
     ]
    }
   ],
   "source": [
    "print(\"Image Shape: \", x_valid.shape)\n",
    "print(\"Masks Shape: \", y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x_train, y_train, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.expand_dims(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 256, 256, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"Simple_PSP.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06403661, 0.12866959, 0.05679062, ..., 0.11094475, 0.14377227,\n",
       "        0.09733662]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03137255, 0.01176471, 0.09803922, ..., 0.        , 0.        ,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = tf.keras.losses.MSE(y_valid[0], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.04307305], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit37f8b3b7665e46429b1e72d24dc4af25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
